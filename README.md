![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)![Google Colab](https://img.shields.io/badge/Google%20Colab-%23F9A825.svg?style=for-the-badge&logo=googlecolab&logoColor=white)![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white)![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white)![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black)

## BipedalWalker-v3 with DDPQ and PPO

В данном коде реализованы 2 метода в обучении с подкреплением (**RL**), а именно: **DDPQ** и **PPO**. Выполнен анализ полученных результатов, в котором происходит сравнение работы 2 методов на базе такой среды, как **BipedalWalker-v3**. Написаны вывод и рекомендации по улучшению модели.

С более подробным описанием кода и блоков кода можно ознакомиться в **Google Colab Notebook**, представленном в данном репозитории.

> Настоятельно рекомендую использовать **графический ускоритель T4** из
> **Google Colab** для запуска этого кода!
